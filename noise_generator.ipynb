{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from model import CNN, IDNGenerator\n",
    "from dataset import MNISTDataset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"MNIST/train.csv\").values\n",
    "dataset = MNISTDataset(csv_file = \"MNIST/train.csv\", transform=transforms.ToTensor())\n",
    "X = torch.tensor(data[:,1:].reshape(-1,1,28,28), dtype=torch.float32)\n",
    "y = torch.tensor(data[:,0], dtype=torch.int64)\n",
    "model = CNN(1, 10)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "p = 0.1\n",
    "epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idn = IDNGenerator(X, y, p, epochs, model, optimizer, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:17<00:00, 47.02it/s, loss=0.0199] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3910123829638386, Accuracy: 93.07142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:18<00:00, 45.36it/s, loss=0.00482] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.07960443613909385, Accuracy: 97.5142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:19<00:00, 42.74it/s, loss=0.0014]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.06311340421518599, Accuracy: 98.11904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:18<00:00, 44.45it/s, loss=0.00102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.053512110707673685, Accuracy: 98.34285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:19<00:00, 43.17it/s, loss=0.00404] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04736038633342278, Accuracy: 98.57619047619048\n"
     ]
    }
   ],
   "source": [
    "new_X, new_y = idn.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42000, 1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_X, 'X_10.pt')\n",
    "torch.save(new_y, 'y_10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X[:1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2onehot(idx, n):\n",
    "\n",
    "    assert torch.max(idx).item() < n\n",
    "\n",
    "    if idx.dim() == 1:\n",
    "        idx = idx.unsqueeze(1)\n",
    "    onehot = torch.zeros(idx.size(0), n).to(idx.device)\n",
    "    onehot.scatter_(1, idx, 1)\n",
    "    \n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_layer_sizes, latent_size, decoder_layer_sizes,\n",
    "                 conditional=False, num_labels=0):\n",
    "\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            encoder_layer_sizes, latent_size, conditional, num_labels)\n",
    "        self.decoder = Decoder(\n",
    "            decoder_layer_sizes, latent_size, conditional, num_labels)\n",
    "\n",
    "    def forward(self, x, c=None):\n",
    "\n",
    "        if x.dim() > 2:\n",
    "            x = x.view(-1, 28*28)\n",
    "\n",
    "        means, log_var = self.encoder(x, c)\n",
    "        z = self.reparameterize(means, log_var)\n",
    "        recon_x = self.decoder(z, c)\n",
    "\n",
    "        return recon_x, means, log_var, z\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        return mu + eps * std\n",
    "\n",
    "    def inference(self, z, c=None):\n",
    "\n",
    "        recon_x = self.decoder(z, c)\n",
    "\n",
    "        return recon_x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_sizes, latent_size, conditional, num_labels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conditional = conditional\n",
    "        if self.conditional:\n",
    "            layer_sizes[0] += num_labels\n",
    "\n",
    "        self.MLP = nn.Sequential()\n",
    "\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            self.MLP.add_module(\n",
    "                name=\"L{:d}\".format(i), module=nn.Linear(in_size, out_size))\n",
    "            self.MLP.add_module(name=\"A{:d}\".format(i), module=nn.ReLU())\n",
    "\n",
    "        self.linear_means = nn.Linear(layer_sizes[-1], latent_size)\n",
    "        self.linear_log_var = nn.Linear(layer_sizes[-1], latent_size)\n",
    "\n",
    "    def forward(self, x, c=None):\n",
    "\n",
    "        if self.conditional:\n",
    "            c = idx2onehot(c, n=10)\n",
    "            x = torch.cat((x, c), dim=-1)\n",
    "\n",
    "        x = self.MLP(x)\n",
    "\n",
    "        means = self.linear_means(x)\n",
    "        log_vars = self.linear_log_var(x)\n",
    "\n",
    "        return means, log_vars\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, layer_sizes, latent_size, conditional, num_labels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.MLP = nn.Sequential()\n",
    "\n",
    "        self.conditional = conditional\n",
    "        if self.conditional:\n",
    "            input_size = latent_size + num_labels\n",
    "        else:\n",
    "            input_size = latent_size\n",
    "\n",
    "        for i, (in_size, out_size) in enumerate(zip([input_size]+layer_sizes[:-1], layer_sizes)):\n",
    "            self.MLP.add_module(\n",
    "                name=\"L{:d}\".format(i), module=nn.Linear(in_size, out_size))\n",
    "            if i+1 < len(layer_sizes):\n",
    "                self.MLP.add_module(name=\"A{:d}\".format(i), module=nn.ReLU())\n",
    "            else:\n",
    "                self.MLP.add_module(name=\"sigmoid\", module=nn.Sigmoid())\n",
    "\n",
    "    def forward(self, z, c):\n",
    "\n",
    "        if self.conditional:\n",
    "            c = idx2onehot(c, n=10)\n",
    "            z = torch.cat((z, c), dim=-1)\n",
    "\n",
    "        x = self.MLP(z)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10 = torch.load(\"noisyData/X_10.pt\").numpy()\n",
    "y_10 = torch.load(\"noisyData/y_10.pt\").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0, 8,  ..., 4, 7, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y.numpy() != y_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::(anonymous namespace)::CvtHelper<cv::impl::(anonymous namespace)::Set<3, 4, -1>, cv::impl::(anonymous namespace)::Set<3, 4, -1>, cv::impl::(anonymous namespace)::Set<0, 2, 5>, cv::impl::(anonymous namespace)::NONE>::CvtHelper(cv::InputArray, cv::OutputArray, int) [VScn = cv::impl::(anonymous namespace)::Set<3, 4, -1>, VDcn = cv::impl::(anonymous namespace)::Set<3, 4, -1>, VDepth = cv::impl::(anonymous namespace)::Set<0, 2, 5>, sizePolicy = cv::impl::(anonymous namespace)::NONE]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 28\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-e411deea21d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Label is {sample_y}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# cv2.waitKey(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# cv2.destroyAllWindows()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::(anonymous namespace)::CvtHelper<cv::impl::(anonymous namespace)::Set<3, 4, -1>, cv::impl::(anonymous namespace)::Set<3, 4, -1>, cv::impl::(anonymous namespace)::Set<0, 2, 5>, cv::impl::(anonymous namespace)::NONE>::CvtHelper(cv::InputArray, cv::OutputArray, int) [VScn = cv::impl::(anonymous namespace)::Set<3, 4, -1>, VDcn = cv::impl::(anonymous namespace)::Set<3, 4, -1>, VDepth = cv::impl::(anonymous namespace)::Set<0, 2, 5>, sizePolicy = cv::impl::(anonymous namespace)::NONE]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 28\n"
     ]
    }
   ],
   "source": [
    "sample_x = X_10[0]\n",
    "sample_y = y_10[0]\n",
    "title = f'Label is {sample_y}'\n",
    "\n",
    "cv2.imshow(title, sample_x.numpy())\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
